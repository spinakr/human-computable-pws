\chapter{Usability Experiment}\label{ch:experiment}
This chapter presents the design and execution of an experiment trying to measure  the performance of the HCP scheme. The experiment is designed as a web application implementing the scheme, allowing participants to test how the scheme would work in practice while measuring how fast and reliable the computation is performed. The application acts as both a demonstration app and a tool for gathering performance data. It has four sections designed to help the participants understand the scheme and get familiar with the computation technique. First, a demonstration video is shown explaining how to compute a password from a challenge, then users are asked to enter some demographic data. Next is the practice section, where users are supposed to practice doing the calculation until feeling comfortable solving challenges without error. Finally is the experiment part, where the calculations are timed and correctness monitored. After finishing the calculations user submit the data and can choose to continue doing more experiments now, or later.
\section{Experiment Objective}
The goal of the experiment is to measure how hard it is for a user to learn the scheme, i.e. how fast and reliable users do the calculations. The experiment measures the calculation times of the participants, and also monitor their progression after several trials. Users should also be able to calculate passwords without too many mistakes. The failure rate is maybe the most important variable to measure; if a user averages more than one mistake for each password calculated the scheme would not work in practice, since most passwords calculated would be wrong. 
\par It is important to note that this project does not see the HCP scheme as a replacement for the widely used standard password managers. It is regarded as a solution for users interested in a secure and reliable way of keeping track of strong passwords, without having to trust a password management service or application. This experiment tests if it is even possible, for users willing to go through the trouble of learning a secret mapping, to use the scheme as an everyday solution.

\par The objectives of the experiment can be summarized as the following.
\begin{itemize}
    \item Measure the average calculation times, both for each participant and for the whole population.
    \item Measure how much users improve after several trials.
    \item Measure the average failure rate for each participant.
\end{itemize}


\section{Method}
The experiment does not try to test any preset hypothesis as it is not clear what to expect regarding either of the tested values. It is not known how hard it is do to the calculations, neither regarding calculation times or failure rates. The results of the experiment does not give an answer, but rather a basis for further data collection through larger scale experiments, for example using crowd sourcing or social medias.

\par Exploratory data analysis (EDA) was introduced by John W. Turkey~\cite{turkey} and involves analysis of data without a prior hypothesis to test. The technique promotes exploration of data to possible find characteristics not previously considered, and essentially suggesting hypotheses to be tested in later surveys or experiments. Velleman and Hoaglin~\cite{exploratory-analysis} describe EDA as a contrast to the formal scientific method involving stating a hypothesis, collecting data and applying a statistical test of the hypothesis. EDA often involves making graphical representations of the data, and then trying to find interesting characteristics and relations. EDA does not conclude with a hypothesis test based on the collected data, but is the first step of an iterative process trying to reveal facts. 

\begin{remark}
 The project does not store any personal information about the participants, and is thus not subject to notification to the "Norwegian Social Science Data Service"\footnote{Is my research project subject to notification? - \url{http://www.nsd.uib.no/nsd/english/pvo.html}}. The experiment only records an anonymous id plus the experiment results consisting of computation time and correctness of the calculations done. Some demographic data is also recorded (age, area of study), but the data can not be connected to person and are thus not regarded as personal information.
 \end{remark}

\par After conducting the experiment, the data is examined and significant characteristics discussed. There are some obvious parameters to explore, including means and standard deviation of the calculation times and failure rate, as well as how these change with practice. 

\par The usability of the scheme directly relies on the calculation time and failure rate as discussed in section \ref{sec:usability}. This can be discussed further after obtaining some numbers giving a picture of what is normal and possible in terms of speed and reliability.


\par A result showing that more than 95\% of all calculations are correct would be promising, since it would mean that approximately 60\% of the passwords calculated would be correct, given length 10 passwords. If the failure rate is significantly worse, the scheme would more often than not be useless since most users would obtain a faulty password when trying to log in. The conclusion of the experiment presented in this project will either way have to be tested more thoroughly, possibly using the same experiment setup or preferably with a throughly random mapping as well. 



\section{Experiment Setup}
The experiment presents and demonstrates the calculation technique to the users, which then is given a chance to practice until fairly familiar with the mechanics. Finally users are asked to calculate a complete password challenge, from which the time spent on each single digit challenge is recorded, as well as if the calculation was correct or not. The practice section allows users to learn through trial and error, using backspace to go back and forth between challenges while also given feedback on the correctness. The experiment view on the other hand does not give any feedback and does not allow user to go back after entering a character. This is done to make sure all mistakes are recorded, even if it is only a miss click. 
\subsection{Secret mapping} The biggest decision made in regards to the experiment design was how to simulate the operation ``recall'' i.e. recalling from memory. It would not be feasible to ask all the participants to memorize a secret mapping beforehand as this would make it very hard to find volunteers. The chosen solution to this problem is to include a ``cheat sheet'' in addition to the displayed challenges, i.e. a list of object to digit mappings shown separately but in the same view as the challenge.
\par After some testing it became apparent that there was a big difference between recalling from memory and actually ``reading'' from a list, which this approach eventually is. To make the operation more similar to the desired recall operation, the mapping was changed from random alphabet positions (e.g A=1, B=2, C=3). This way one does not always have to read in the table to know the mapping. Most users will be able to know instantly what the mapping for at least the first and eventually, after some practice, all the letters, much easier than with a random mapping. The is the closest way of mimicking the actual operations of the scheme without having the participants memorize an actual mapping. It is not in any way certain that this shortcut reflect the real world act of recalling from memory, but it is assumed to be ``close enough'' for the experiment. 
\begin{remark}
The author of this project did memorize a mapping of both 10 and later 20 mappings without significantly different calculation times compared to using the alphabet positions.
\end{remark}

\subsection{Participants}
The participants for the experiment were chosen mostly from people known by the author, this limits the number of participants somewhat. This was done to ensure the quality of the data samples. The experiment could have been distributed through crowd sourcing services or social media, probably increasing the number of participants drastically. The problem with this approach, and the reason for not doing it, is that the experiment requires absolute concentration which can not be assured from ``casual'' participants accessing the experiment through a link posted on facebook. Since every participant calculates 10 single digit challenges for each trial of the experiment, there is still a decent amount of data samples, even with relatively few participants. 
\par Even if the experiment might be limited by the number of participants, the results are still considered to be interesting. Since the scheme tested is not supposed to be a widely-deployed password manager, it might be sufficient if the experiment can show that some users are able achieve what is considered sufficient usability. It should also be noted that most of the participants are regarded above average in mathematics. This might be a strength or a weakness of the experiment as it does not represent a wide range of the population, but the calculation times should at least be stronger than average.


\section{Web Application}
The experiment application is similar in design to the Chrome extension presented in \autoref{app}, but implemented as a web application. It is implemented using the AngularJS framework (as described in \autoref{app}) and a mongoDB\footnote{mongoDB - \url{https://www.mongodb.org/}} database to store the results, a cookie in the users' browser is used to keep track of users across trials. 

\par The application consists of four sections to flip through, with the last one being the actual experiment. First, users are presented with a video demonstration of the scheme and instructions on how to calculate passwords. The slides used to instruct users can be seen in \autoref{demo-slides}. After watching the demo, users are asked to enter some demographic data (age and occupation). Next, is a section which looks the same as the experiment, but without the actual recording of data, this is the practice section. The purpose of this section is to give users a chance to verify that they have understood the scheme and are actually able to calculate passwords. When users are ready to start the experiment, they can continue on to the actual experiment, which is the final view. The experiment is exactly like the practice section, without response on correctness and redo capabilities, with backspace deactivated. The first sample of the experiment is not counted towards the results, allowing users to get ready and start when they feel like it. 


\par Section \ref{computation-time} discusses how a single digit challenge can be presented to users in a logical way, possibly making it more efficient to calculate. The experiment uses a similar layout to the one shown in \autoref{challenges} and also as in the Chrome extension in chapter \ref{app}. The challenges update in the same way as in the chrome extension so users should be able to calculate the responses continuously. The calculation time is recorded for each single digit challenge computed, together with a boolean value representing if the result was correct or not. 
\par Figure \ref{complete-experiment} shows the screen after completing a trial of the experiment, next users will push the submit button and the sample would be saved in the database together with a random identification stored in a cookie in the users' browsers. Users can then redo the experiment several times keeping the same id, making it possible to track each participant's development.

\begin{figure}[h]
    \includegraphics[width=\textwidth]{complete-experiment}
    \caption{The experiment screen seen after completing an experiment sample, ready to be submitted.}
    \label{complete-experiment}
\end{figure}

\par As for the storage of results a noSQL database called MongoDB is used. After completing a trial of the experiment a Javascript object is stored in the database, \autoref{db-obj} shows an example of this object. Note the \emph{hcp\_id} field which is fetched from a cookie in the participants' browsers, making it persist across several trials. 

\par The views of the web application can be seen in \autoref{experiment-views} or by visiting the hosted experiment site at \url{hcp.sp1nakr.com}.

\begin{table}
\begin{tabular}{|c|c|}
    \hline
    hcp\_id & 1b7aa17ea0  \\ \hline
    occupation & Technology student \\ \hline
    age & 27 \\ \hline
    results & $[1,1,1,1,1,1,1,1,1,1]$ \\ \hline
    calcTimes & $[12.047,7.115,8.022,9.283,10.544,8.807,9.925,9.78,7.11,8.187]$ \\ \hline
\end{tabular}
\caption{Experiment object after completing a trial, as stored in the database.}
\label{db-obj}
\end{table}

\section{Results}

This section presents the results of the conducted experiment and investigate the characteristics of the data recorded. The focus is on the calculation times and failure rates, which both are important factors in the resulting usability of the scheme, as discussed in \autoref{sec:usability}.
\par The observations made are not necessarily representative for all users, because of the relatively small number of samples ($467$ single digit challenges), but it is still interesting to investigate the consequences of the results. Even if the results show that the scheme achieves a lower level of usability than what are considered acceptable, it might still function well for some users with the right amount of practice. The limitations of the experiment is discussed, in addition to results and the consequences of these.

\subsection{Calculation times.}
How fast a user is able to calculate the response to a single digit challenge is a concrete measure of the usability of the scheme. Figure \ref{histo-calctimes} shows the distribution of calculation times of all the experiment samples, the calculated average off all the $467$ trials are $10.296$ seconds. The median value is $9.406$ with standard deviation of $3.64$ which also can be observed in the figure. 
\par Recall conjecture \ref{conjecture1} from \autoref{human-func}. The function $f$ (see definition \ref{fo-function}) used in this project is $(P,9,3)$-computable. The conjecture then defines the variable $\gamma_H$ for user $H$ as {\Large $\gamma_H = \frac{\hat t}{9}$}. 
\par The average $\gamma$ of all the participants are $\tilde \gamma = \frac{10.104}{9} = 1.227$. This is slightly higher than the $7.5$ seconds ($\gamma_H \le 1 $) Blocki~\cite{hcp-blocki} predicts that users with moderate mathematical backgrounds should achieve. It is still not unreasonably high, and should not be a direct hindrance. Calculating a 10 character password would for example take $10 \cdot 10 = 100$ seconds, just above $1.5$ minutes, to calculate, 15 character would take $2.5$ minutes. On average spending 2-3 minutes calculating a password might seem like a lot, but users concerned about the security of their accounts, might be willing to make this trade-off. Especially if users are worried about putting passwords in the hands of a online service to store persistently (e.g. \emph{lastpass.com}), might be willing to put quite some time into calculating passwords instead.
\par It is also relevant to study the evolution of each user in terms calculation times. Figure \ref{scatter-regression} illustrates the average calculation time for each $i$th trail per user. $i=1$ represent the average of the first calculation done by each user, $i=2$ the second calculation etc. The figure clearly illustrates that the averages decrease with practice. This could have been expected, since users will be more and more familiar with the calculation procedure for each trial. The consequence of this observation is that the average calculation time, and consequently $\gamma$, would be significantly lower if the participants got more practice with the scheme before their results was recorded. Each participant averaged $33$ samples each, so it is not feasible to e.g. calculate the average after removing the 20 first calculations from each participant, as this would leave very few trials. The important goal of the experiment is though not to find an accurate average calculation time, but to verify that $\gamma_H \le 1$ is achievable. It seems that the average most likely is somewhere between 9 and 11 seconds, depending on how long users have been using the scheme, which is not severely limiting.
\par Figure \ref{user-regression} and table \ref{tbl:bestuser} shows the 7 participants with the most samples, the same effect can be observed, all except from one participant have a downward going trend (see SCT in table \ref{tbl:bestuser}).

\begin{table}[h]
    \centering
\begin{tabular}{|c|c|c|c|c|}
    \hline
     SMP & MCT & SDCT & SCT & MFR \\ \hline \hline
    $72$ & $9.02$ & $2.38$ & $-0.015$ & $0.0695$\\\hline
    $36$ & $10.06$ & $3.24$ & $0.038$ & $0.1944$\\\hline
    $72$ & $9.62$ & $2.79$ & $-0.373$ & $0.0278$\\\hline
    $45$ & $10.33$ & $3.33$ & $-0.115$ & $0.044$\\\hline
    $45$ & $10.06$ & $3.31$ & $-0.068$ & $0.089$\\\hline
    $36$ & $9.89$ & $3.34$ & $-0.143$ & $0.083$\\\hline
    $45$ & $9.88$ & $3.33$ & $-0.023$ & $0.022$\\\hline

\end{tabular}
\caption{Table of the 7 best participants. SMP=sample size, MCT=mean calculation time, SDCT=standard deviation of calculation time, SCT=slope calculation time, MFR=mean failure rate. }
\label{tbl:bestuser}
\end{table}


\begin{figure}
    \centering
    \begin{tikzpicture}
        \begin{axis}[width=\textwidth, xlabel=Calculation times in seconds. ,ybar, ymin=0, ylabel=Number of single digit challenges.]
            \addplot +[
                    hist = {
                        bins=25,
                        data min=3,
                        data max=20
                    },
                    fill=blue!60
                ]table [y index=0]{calcTimes2.csv};

        \end{axis}
    \end{tikzpicture}
    \caption{Histogram showing the distribution of calculation times of all the recorded experiments. Sample size $467$ single digit challenges.}
    \label{histo-calctimes}
\end{figure}


\begin{figure}
    \centering
\begin{tikzpicture}
    \begin{axis}[
                enlargelimits=false,
                xlabel=Trial number: $i$,
                ylabel = Average calculation time in seconds.,
                width=\textwidth,
                ymin=4,
                ymax=18
        ]
        \addplot+[
                only marks,
                scatter,
                mark size=1.5pt
            ]
            table[meta=avg]
            {sum-avgs2.dat};
        \addplot[
            domain=0:80,
            samples=3,
            very thick
        ]{11.42687437-0.05270738*x};
    \end{axis}

\end{tikzpicture}
\caption{Average calculation time of all participants' $i'th$ calculation sample, and the regression line of the averages. Sample size $467$, average samples per participant $33$.}
\label{scatter-regression}
\end{figure}


\begin{figure}
    \centering
\begin{tikzpicture}
    \begin{axis}[
                enlargelimits=false,
                xlabel=Trial number: $i$,
                ylabel = Calculation time in seconds.,
                width=\textwidth,
                ymin=4,
                ymax=16
        ]
        \addplot[
            domain=0:72,
            samples=3,
            thick,
            color=red!50
        ]{9.572-0.015535*x};
        \addplot[
            domain=0:36,
            samples=3,
            thick,
            color=green!50
        ]{11.46978+0.03817*x};
        \addplot[
            domain=0:72,
            samples=3,
            thick,
            color=yellow!50
        ]{10.29454-0.037335*x};
        \addplot[
            domain=0:45,
            samples=3,
            thick,
            color=blue!50
        ]{15.6977-0.1146*x};
        \addplot[
            domain=0:45,
            samples=3,
            thick,
            color=purple!50
        ]{10.15532-0.06755*x};
        \addplot[
            domain=0:36,
            samples=3,
            thick,
            color=violet!50
        ]{11.12582-0.143408*x};
        \addplot[
            domain=0:45,
            samples=3,
            thick,
            color=cyan!50
        ]{9.04245-0.023411*x};
    \end{axis}

\end{tikzpicture}
\caption{Regression lines for the 7 participants with the most samples. A clear downward sloping trend in terms of calculation time is observed.}
\label{user-regression}
\end{figure}



\subsection{Failure rate.}
Failure rate is a key characteristic of the scheme. As mentioned it is essential that a user is able to calculate passwords correctly for the scheme to function. How high the failure rate can be depends on how long passwords are used and how often a user can enter the wrong password without locking the account. A typical password protected site will allow a minimum of three strikes before the account is locked~\cite{10-strikes}. It is thus important that the probability of being ``locked out'' is small enough for it not to happen often, how often is of course subject to discussion.

\begin{observation}\label{obs:failrate}
    Average failure rate for all samples recorded in the experiment was measured to be $\tilde \lambda = 0.0584795321637$, approximately every one out of 17 single digit challenge was calculated wrong.
\end{observation}
This observation might not seem very unusual, but since a password consists of a sequence of calculations, it is required that users calculate a given number of challenges consecutively without failure. It is thus more interesting to evaluate the probability of having at least one mistake in a complete password calculation sequence. It is also not unusual to enforce a password policy using a three-strike policy which locks the account if three consecutive mistakes are made. Next, these probabilities are presented and discussed. 


The probability of having at least one mistake in a length $l$ password given the failure rate $\lambda$ is given by
\begin{equation}\label{eq:failrate}
    P(fail) = 1 - (1 - \lambda)^l
\end{equation}

Next, the probability of getting the account locked given a three-strike policy with the same password and failure rate is 
\begin{equation}\label{eq:lockrate}
    P(lock) = ( 1 - (1 - \lambda)^l )^3
\end{equation}


\begin{table}[h]
    \centering
\begin{tabular}{|c|c|c|c|c|}
    \hline
    Password length $l$ & $3$ & $5$ & $10$ & $15$ \\ \hline \hline
    $P(fail)$ & $0.1654$ & $0.2601$ & $0.4526$ & $0.5959$ \\ \hline
    $P(lock)$ & $0.0045$ & $0.0176$ & $0.0927$ & $0.2107$ \\ \hline
\end{tabular}
\caption{Probability of having at least one mistake in a length $l$ password given failure rate $\lambda = 0.0584795321637$ for each single digit challenge.}
\label{tbl:failrate}
\end{table}
 
\par Observation \ref{tbl:failrate} shows the probabilities of calculating a password wrong once and three times in a row. If users want to use a password of 15 characters, which is reasonable to assume since the scheme only produce digits, they will compute a faulty password nearly 60\% of the time. This limits the usability severely, since users will more often than not, be unable to log in.
\par The probability of actually locking the account by miscalculating three passwords in a row, is lower but not significantly. With the same failure rate and password length, users would break the three-strike rule approximately one out of five login attempts.

\par To illustrate this consequence in a extreme case, consider the \emph{very active} user from table \ref{users} in section \ref{sec:usability} who visits 10 different accounts every day. Such an user would eventually lock two accounts every day with password lengths of 15 characters, which of course is not acceptable.

\par As discussed in \autoref{improving-usab} (and as implemented in \autoref{app}), the password length needed for different accounts may vary. By using shorter password for noncritical accounts, and only generating long passwords for the most critical, the average password length will be much lower than in the examples above. The scheme could then be tweaked by users to fit specific needs, instead of requiring 10 or 15 characters in all passwords generated. For less sensitive accounts users may have passwords of lengths 5, which would make for a mistake in approximately every 4th password, and only locking an account every 57th login attempt. This way users can calculate passwords with significantly less effort and lower failure rates. 

\par The experiment did not find any significant correlation between failure rates and calculation times. Users calculating fast do not have a higher failure rate than slower users, which some might expected. 

%\subsection{Improvement Measures.}
%\par Blocki et al.~\cite{hcp-blocki} suggests a tweak to the scheme with the purpose of decreasing the calculation time while still ensuring resistance against dictionary attacks. The suggestion is to memorize another mapping $w:\mathbb{Z}_{10} \rightarrow \{x\}$ with $x$ being one of the $10000$ most common English words. Then after computing $f(\sigma(C))$ the user would apply $w$ giving the corresponding word to the digit. The point of doing this is to save time when calculating, but it also solves the problem with high failure rates. Blocki argues, it would be sufficient with 3-5 challenges. With this assumption that 3-5 calculations are enough, the scheme would function significantly better. 
%\par Using the same example with the very active user, an account would be locked every 222nd login attempt with length 3 and every 57th with length 5. This would be a huge improvement, actually making the scheme usable.


\begin{remark}
    The author remarks that the findings related to failure rates might be too harsh since the participants was asked to calculate the challenges ``as fast as possible'', which might be the wrong approach. In a real world scenario it would be more important to calculate correctly. Though, the results clearly show that the failure rate is a relevant attribute worth investigating closer, as it might limit the reliability of the scheme in real usecases.
\end{remark}



